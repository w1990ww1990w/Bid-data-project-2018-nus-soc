{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/usr/local/spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import pandas as pd\n",
    "import re\n",
    "from operator import add\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish processing Questions.csv\n"
     ]
    }
   ],
   "source": [
    "questionOriginalFile = pd.read_csv(\"_Questions.csv\",encoding=\"latin-1\", iterator = True, chunksize=100)\n",
    "hasHeader = False\n",
    "\n",
    "os.remove(\"Questions.csv\")\n",
    "for chunk in questionOriginalFile:\n",
    "    chunk[\"Body\"] = chunk[\"Body\"].map(lambda body: body.replace(\"\\n\", \" \"))\n",
    "    chunk[\"Body\"] = chunk[\"Body\"].map(lambda body: body.replace(\",\", \";\"))\n",
    "    if hasHeader:\n",
    "        chunk.to_csv(\"Questions.csv\", mode = \"a\", encoding=\"utf-8\", header=False, index = False)\n",
    "    else:\n",
    "        chunk.to_csv(\"Questions.csv\", mode = \"a\", encoding=\"utf-8\", header=True, index = False)\n",
    "print(\"finish processing Questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish processing Answers.csv\n"
     ]
    }
   ],
   "source": [
    "answerOriginalFile = pd.read_csv(\"_Answers.csv\",encoding=\"latin-1\", iterator = True, chunksize=100)\n",
    "hasHeader = False\n",
    "\n",
    "os.remove(\"Answers.csv\")\n",
    "for chunk in answerOriginalFile:\n",
    "    chunk[\"Body\"] = chunk[\"Body\"].map(lambda body: body.replace(\"\\n\", \" \"))\n",
    "    chunk[\"Body\"] = chunk[\"Body\"].map(lambda body: body.replace(\",\", \";\"))\n",
    "    if hasHeader:\n",
    "        chunk.to_csv(\"Answers.csv\", mode = \"a\", encoding=\"utf-8\", header=False, index = False)\n",
    "    else:\n",
    "        chunk.to_csv(\"Answers.csv\", mode = \"a\", encoding=\"utf-8\", header=True, index = False)\n",
    "print(\"finish processing Answers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish reading files\n"
     ]
    }
   ],
   "source": [
    "# questionFile=sc.textFile(\"Questions.csv\")\n",
    "questionFile=sc.textFile(\"test_q.csv\")\n",
    "# answerFile=sc.textFile(\"Answers.csv\")\n",
    "answerFile=sc.textFile(\"test_a.csv\")\n",
    "# tagFile = sc.textFile(\"Tags.csv\")\n",
    "tagFile = sc.textFile(\"test_t.csv\")\n",
    "stopWordsFile = sc.textFile(\"stopwords.txt\")\n",
    "print(\"finish reading files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "questionWithHeader = questionFile.map(lambda line: line.split(\",\")).filter(lambda line: len(line)>1)\n",
    "header = questionWithHeader.first()\n",
    "question = questionWithHeader.filter(lambda x: x != header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWordsList = stopWordsFile.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "questionLower = question.map(lambda x: (x[0], (x[5]+x[6]).lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n"
     ]
    }
   ],
   "source": [
    "def f(x): return re.sub('[^a-zA-Z]+', ' ', x)\n",
    "questionLower = questionLower.mapValues(f)\n",
    "print(questionLower.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7996\n"
     ]
    }
   ],
   "source": [
    "def f2(x): return x.split(\" \")\n",
    "questionPairRaw = questionLower.flatMapValues(f2)\n",
    "print(questionPairRaw.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3998\n"
     ]
    }
   ],
   "source": [
    "questionPair=questionPairRaw.filter(lambda x: x[1] not in stopWordsList)\n",
    "print(questionPair.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3889\n"
     ]
    }
   ],
   "source": [
    "questionPairfilter=questionPair.filter(lambda x:x[1]!=\"\")\n",
    "print(questionPairfilter.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1919\n"
     ]
    }
   ],
   "source": [
    "questionPairStage1 = questionPairfilter.map(lambda x:(x[0]+\"@\"+x[1],1)).reduceByKey(add)\n",
    "print(questionPairStage1.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1919\n"
     ]
    }
   ],
   "source": [
    "print(questionPairStage1.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n"
     ]
    }
   ],
   "source": [
    "N = questionLower.count()\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('80@execute', 4), ('80@multiple', 2), ('80@statement', 2), ('80@database', 1), ('80@generation', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(questionPairStage1.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('execute', '80=4'), ('multiple', '80=2'), ('statement', '80=2'), ('database', '80=1'), ('generation', '80=1')]\n"
     ]
    }
   ],
   "source": [
    "questionPairStage2MapPhase = questionPairStage1.map(lambda x:(x[0].split(\"@\")[1],x[0].split(\"@\")[0]+\"=\"+str(x[1])))\n",
    "print(questionPairStage2MapPhase.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2Map = questionPairStage2MapPhase.countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(stage2Map.get('execute'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('execute@80', 11.128338413705677), ('multiple@80', 5.548688364952579), ('statement@80', 6.035776454821954), ('database@80', 2.583997552432231), ('generation@80', 4.663439094112067)]\n"
     ]
    }
   ],
   "source": [
    "questionPairStage2 = questionPairStage2MapPhase.map(lambda x:(x[0]+\"@\"+x[1].split(\"=\")[0],(1+np.log(int(x[1].split(\"=\")[1])))*np.log(N/stage2Map.get(x[0]))))\n",
    "print(questionPairStage2.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('80', 'execute=11.128338413705677'), ('80', 'multiple=5.548688364952579'), ('80', 'statement=6.035776454821954'), ('80', 'database=2.583997552432231'), ('80', 'generation=4.663439094112067')]\n"
     ]
    }
   ],
   "source": [
    "questionPairStage3MapPhase = questionPairStage2.map(lambda x:(x[0].split(\"@\")[1],x[0].split(\"@\")[0]+\"=\"+str(x[1])))\n",
    "print(questionPairStage3MapPhase.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('180', 229.7145562811237), ('330', 1341.3598263114907), ('470', 448.5714876428375), ('580', 2123.868076874934), ('930', 170.42691150448204)]\n"
     ]
    }
   ],
   "source": [
    "def f3_1(a,b): return float(a)+float(b.split(\"=\")[1])*float(b.split(\"=\")[1])\n",
    "def f3_2(a,b): return float(a)+float(b)\n",
    "questionPairStage3AggByKey = questionPairStage3MapPhase.aggregateByKey(0.0,f3_1,f3_2)\n",
    "print(questionPairStage3AggByKey.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.038131748297413\n"
     ]
    }
   ],
   "source": [
    "stage3Map = questionPairStage3AggByKeysqr.collectAsMap()\n",
    "print(stage3Map.get('90'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('80', 'execute=0.18639896556738128'), ('80', 'multiple=0.09294017965962616'), ('80', 'statement=0.10109887440061487'), ('80', 'database=0.04328179579880556'), ('80', 'generation=0.07811231028509996'), ('80', 'http=0.061783416134000416'), ('80', 'en=0.0770694152873754'), ('80', 'wikipedia=0.10109887440061487'), ('80', 'wiki=0.10109887440061487'), ('80', 'adobe=0.13956220568671052')]\n"
     ]
    }
   ],
   "source": [
    "questionPairStage3 = questionPairStage3MapPhase.map(lambda x:(x[0],x[1].split(\"=\")[0]+\"=\"+str(float(x[1].split(\"=\")[1])/stage3Map.get(x[0]))))\n",
    "print(questionPairStage3.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('180', ['wheels=0.3076890572649864', 'pseudo=0.3076890572649864', 'solved=0.3076890572649864', 'stuck=0.3076890572649864', 'distinguishable=0.3076890572649864', 'parameter=0.2619558980603028', 'g=0']), ('330', ['classes=0.3193517411118351', 'video=0.227500315486462', 'workhorse=0.2155898812650258', 'book=0.2155898812650258', 'mine=0.18354582207600814', 'pause=0.12733085684478265', 'encoding=0.12733085684478265']), ('470', ['homegrown=0.3728079699966661', 'services=0.284981923834969', 'ready=0.22018639269940712', 'numerous=0.22018639269940712', 'opposed=0.22018639269940712', 'auto=0.22018639269940712', 'creates=0.22018639269940712']), ('580', ['live=0.2825013570494739', 'products=0.17133151385886897', 'scripts=0.17133151385886897', 'enterprise=0.17133151385886897', 'manager=0.17133151385886897', 'express=0.17133151385886897', 'gate=0.17133151385886897']), ('930', ['connect=0.5149298451290975', 'simplest=0.3572211977022691', 'loop=0.3572211977022691', 'recordset=0.3572211977022691', 'query=0.2339376451341581', 'f=0', 'g=0'])]\n"
     ]
    }
   ],
   "source": [
    "num_keywords = 7\n",
    "def f4_1(a,b):\n",
    "    c=[]\n",
    "    for i in range(num_keywords):\n",
    "        if float(b.split(\"=\")[1])>float(a[i].split(\"=\")[1]):\n",
    "            a[i]=b\n",
    "            break\n",
    "    return a\n",
    "def f4_2(a,b):\n",
    "    for i in range(num_keywords): #b\n",
    "        for j in range(num_keywords): #a\n",
    "            if float(b[i].split(\"=\")[1])>float(a[j].split(\"=\")[1]):\n",
    "                a[j] = b[i]\n",
    "                break\n",
    "    return a\n",
    "questionPairStage4 = questionPairStage3.aggregateByKey([\"a=0\",\"b=0\",\"c=0\",\"d=0\",\"e=0\",\"f=0\",\"g=0\"],f4_1,f4_2)\n",
    "print(questionPairStage4.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "outMap=questionPairStage4.collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['organization', 'ul', 'confirm', 'big', 'sqlstatement', 'wheel', 'languages', 'event', 'manager', 'syntax', 'providers', 'stacks', 'matching', 'objects', 'site', 'programming', 'best', 'ux', 'simple', 'create', 'explaining', 'dns', 'payload', 'times', 'heard', 'update', 'parameter', 'autocomplete', 'dataset', 'bit', 'updating', 'querying', 'simplest', 'ends', 'structure', 'homegrown', 'stuck', 'sqlconnection', 'cmdlets', 'replace', 'numerous', 'rspec', 'supports', 'stored', 'respective', 'bazaar', 'query', 'mysql', 'studio', 'terms', 'peak', 'hkey', 'verifications', 'resolvepath', 'trim', 'ado', 'icard', 'version', 'purchased', 'catching', 'winforms', 'cards', 'property', 'aix', 'c', 'values', 'bean', 'messy', 'br', 'today', 'questions', 'hashmaps', 'attempt', 'table', 'dim', 'gt', 'wheels', 'moment', 'datagrid', 'embedding', 'recordset', 'connect', 'net', 'simply', 'pm', 'choice', 'video', 'ruby', 'liba', 'playing', 'array', 'customusername', 'core', 'subversion', 'solo', 'cms', 'traverse', 'canonicalization', 'kbd', 'fogbugz', 'encoding', 'logically', 'postback', 'formattedstring', 'ms', 'services', 'seework', 'generate', 'close', 'locked', 'things', 'triggers', 'workhorse', 'object', 'displayed', 'compiled', 'publickeytoken', 'unit', 'onkeypress', 'rel', 'ironruby', 'surprise', 'sales', 'ready', 'd', 'menu', 'speeding', 'blending', 'microsoft', 'target', 'merging', 'subdomain', 'joins', 'shared', 'pseudo', 'code', 'card', 'php', 'specific', 'varchar', 'asterisk', 'field', 'task', 'framework', 'scripts', 'torgb', 'src', 'htaccess', 'presumably', 'book', 'g', 'regex', 'allow', 'send', 'handles', 'straight', 'community', 'database', 'prototype', 'match', 'complicated', 'vectors', 'solaris', 'porv', 'todo', 'free', 'forums', 'views', 'wmi', 'major', 'getters', 'tortoisesvn', 'telligent', 'third', 'exceptions', 'windows', 'tables', 'tools', 'coverage', 'datatable', 'global', 'soloing', 'example', 'classes', 'writing', 'clicking', 'ol', 'internet', 'realize', 'points', 'box', 'release', 'blockquote', 'system', 'trouble', 'branchmerge', 'unsupported', 'datastructures', 'signed', 'server', 'method', 'modifiers', 'vsz', 'add', 'libb', 'registry', 'regexoptions', 'exactly', 'js', 'machine', 'lt', 'versions', 'build', 'local', 'datatables', 'device', 'sitemap', 'form', 'organize', 'codes', 'ordering', 'products', 'procs', 'collection', 'li', 'solution', 'browse', 'asp', 'procedures', 'cc', 'figuring', 'language', 'class', 'xml', 'setters', 'pointed', 'source', 'bin', 'address', 'suffice', 'uncomfortable', 'opposed', 'sharepoint', 'basecamp', 'paper', 'hkcu', 'base', 'echo', 'handling', 'locking', 'setter', 'live', 'postgresql', 'hand', 'subquery', 'sql', 'solved', 'faster', 'queries', 'management', 'msbuild', 'story', 'edit', 'paging', 'emma', 'based', 'folder', 'gridview', 'string', 'size', 'blend', 'readings', 'good', 'refresh', 'properly', 'modify', 'bring', 'hp', 'eclipse', 'input', 'analysis', 'initial', 'testing', 'creating', 'namespace', 'figure', 'visual', 'column', 'ps', 'newhour', 'em', 'classic', 'fairly', 'creates', 'prone', 'suspect', 'layer', 'appealing', 'barebones', 'redistributable', 'comparable', 'control', 'stream', 'white', 'backticks', 'md', 'crap', 'assemblyversion', 'wise', 'design', 'spec', 'location', 'uhwc', 'f', 'web', 'incremented', 'delta', 'packages', 'viewstate', 'void', 'git', 'pause', 'whois', 'mine', 'express', 'daterequired', 'color', 'branching', 'return', 'years', 'email', 'enterprise', 'processcmdkey', 'search', 'changes', 'interacts', 'practice', 'columns', 'title', 'ccnet', 'stl', 'description', 'restore', 'hashbytes', 'storage', 'suggested', 'reasons', 'wrapped', 'bodmas', 'deques', 'disable', 'e', 'love', 'utility', 'urple', 'nonquery', 'favorite', 'njc', 'auto', 'overhead', 'reason', 'wildcard', 'users', 'versus', 'netcmdlets', 'dlls', 'delete', 'view', 'loop', 'rake', 'wiki', 'visualise', 'strsql', 'effective', 'asax', 'username', 'support', 'service', 'bll', 'row', 'gate', 'learn', 'decent', 'distinguishable', 'process', 'informed', 'strong', 'painted', 'hours', 'personal', 'clauses', 'treemaps', 'suite', 'glance', 'nant']\n"
     ]
    }
   ],
   "source": [
    "# mock expected keywords\n",
    "keywords=list(set(questionPairStage4.map(lambda x: list(map((lambda x: x.split(\"=\")[0]), x[1]))).reduce(add)))\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" I've written a database generation script in SQL and want to execute it in my Adobe AIR application Create Table tRole roleID integer Primary Key roleName varchar Create Table tFile fileID integer Primary Key fileName varchar fileDescription varchar thumbnailID integer fileFormatID integer categoryID integer isFavorite boolean dateAdded date globalAccessCount integer lastAccessTime date downloadComplete boolean isNew boolean isSpotlight boolean duration varchar Create Table tCategory categoryID integer Primary Key categoryName varchar parent categoryID integer I execute this in Adobe AIR using the following methods public static function RunSqlFromFile fileName String void var file File File applicationDirectory resolvePath fileName var stream FileStream new FileStream stream open file FileMode READ var strSql String stream readUTFBytes stream bytesAvailable NonQuery strSql public static function NonQuery strSQL String void var sqlConnection SQLConnection new SQLConnection sqlConnection open File applicationStorageDirectory resolvePath DBPATH var sqlStatement SQLStatement new SQLStatement sqlStatement text strSQL sqlStatement sqlConnection sqlConnection try sqlStatement execute catch error SQLError Alert show error toString No errors are generated however only tRole exists It seems that it only looks at the first query up to the semicolon if I remove it the query fails Is there a way to call multiple queries in one statement \"]\n"
     ]
    }
   ],
   "source": [
    "newQuestion = sc.wholeTextFiles(\"new_q.txt\")\n",
    "newQuestion = newQuestion.map(lambda x: re.sub('\\n', ' ', x[1]))\n",
    "newQuestion = newQuestion.map(lambda x: re.sub('<.*?>', ' ', x))\n",
    "newQuestion = newQuestion.map(lambda x: re.sub('[^a-zA-Z\\']+', ' ', x))\n",
    "\n",
    "print(newQuestion.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('written', 'new=1'), ('database', 'new=1'), ('generation', 'new=1'), ('script', 'new=1'), ('sql', 'new=1'), ('execute', 'new=3'), ('adobe', 'new=2'), ('air', 'new=2'), ('application', 'new=1'), ('create', 'new=3')]\n"
     ]
    }
   ],
   "source": [
    "newQuestionKeywordsStageOne = newQuestion.flatMap(lambda x: x.lower().split(\" \")).filter(lambda x: x != '' and x not in stopWordsList).map(lambda x: (x, 1)).reduceByKey(add).map(lambda x: (x[0], 'new=' + str(x[1])))\n",
    "print(newQuestionKeywordsStageOne.take(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('written', 3.574216545793796), ('database', 2.4756042571256867), ('generation', 3.979681653901961), ('script', 3.0633909220278057), ('sql', 2.033771504846648), ('execute', 8.351808823865683), ('adobe', 6.051674667221473), ('air', 6.738186771830246), ('application', 2.4756042571256867), ('create', 5.442514441908174)]\n"
     ]
    }
   ],
   "source": [
    "newQuestionKeywordsStageTwoMap = newQuestionKeywordsStageOne.union(questionPairStage2MapPhase).countByKey()\n",
    "\n",
    "newQuestionKeywordsStageTwo = newQuestionKeywordsStageOne.map(lambda x: (x[0], (1 + np.log(int(x[1].split(\"=\")[1]))) * np.log((N + 1)/newQuestionKeywordsStageTwoMap.get(x[0]))))\n",
    "print(newQuestionKeywordsStageTwo.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('written', 0.07247168990263128), ('database', 0.050195958119879744), ('generation', 0.08069299972106751), ('script', 0.06211406446903707), ('sql', 0.04123724904287243), ('execute', 0.16934332082412465), ('adobe', 0.12270523742905481), ('air', 0.13662512496864992), ('application', 0.050195958119879744), ('create', 0.11035375553524643), ('table', 0.11035375553524643), ('trole', 0.13662512496864992), ('roleid', 0.08069299972106751), ('integer', 0.22317233248190185), ('primary', 0.16934332082412465), ('key', 0.13984853817968554), ('rolename', 0.08069299972106751), ('varchar', 0.18911037521009366), ('tfile', 0.08069299972106751), ('fileid', 0.08069299972106751), ('filename', 0.16934332082412465), ('filedescription', 0.08069299972106751), ('thumbnailid', 0.08069299972106751), ('fileformatid', 0.08069299972106751), ('categoryid', 0.16934332082412465), ('isfavorite', 0.08069299972106751), ('boolean', 0.19255725021623232), ('dateadded', 0.08069299972106751), ('globalaccesscount', 0.08069299972106751), ('lastaccesstime', 0.08069299972106751), ('downloadcomplete', 0.08069299972106751), ('isnew', 0.08069299972106751), ('isspotlight', 0.08069299972106751), ('duration', 0.08069299972106751), ('tcategory', 0.08069299972106751), ('categoryname', 0.08069299972106751), ('parent', 0.08069299972106751), ('methods', 0.06211406446903707), ('public', 0.1051682531288688), ('static', 0.11282892004536968), ('function', 0.09361693687426799), ('runsqlfromfile', 0.08069299972106751), ('string', 0.12259519636576749), ('void', 0.13662512496864992), ('var', 0.21056337274018783), ('file', 0.13721508971812602), ('applicationdirectory', 0.08069299972106751), ('resolvepath', 0.13662512496864992), ('stream', 0.19255725021623232), ('filestream', 0.13662512496864992)]\n"
     ]
    }
   ],
   "source": [
    "newQuestionKeywordsStageThreeSquare = newQuestionKeywordsStageTwo.map(lambda x: np.square(x[1])).reduce(add)\n",
    "\n",
    "newQuestionKeywordsStageThree = newQuestionKeywordsStageTwo.map(lambda x: (x[0], x[1]/np.sqrt(newQuestionKeywordsStageThreeSquare)))\n",
    "print(newQuestionKeywordsStageThree.take(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sqlconnection', 0.22527544607170702), ('sqlstatement', 0.22527544607170702), ('stream', 0.19255725021623232), ('strsql', 0.19255725021623232), ('varchar', 0.18911037521009366), ('void', 0.13662512496864992), ('resolvepath', 0.13662512496864992), ('nonquery', 0.13662512496864992), ('string', 0.12259519636576749), ('create', 0.11035375553524643), ('table', 0.11035375553524643), ('query', 0.09890903250577458), ('queries', 0.058417267938315975), ('database', 0.050195958119879744), ('sql', 0.04123724904287243)]\n"
     ]
    }
   ],
   "source": [
    "newQuestionKeywordsStageFour = newQuestionKeywordsStageThree.filter(lambda x: x[0] in keywords).sortBy(lambda x: -x[1])\n",
    "print(newQuestionKeywordsStageFour.take(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sqlconnection', 'sqlstatement', 'stream', 'strsql', 'varchar']\n"
     ]
    }
   ],
   "source": [
    "# mock expected questions inside buckets <Qi, sum(Ai)>\n",
    "candidateSimilarQuestions = newQuestionKeywordsStageFour.map(lambda x: x[0])\n",
    "print(candidateSimilarQuestions.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "from datasketch.minhash import MinHash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
