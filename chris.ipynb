{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/usr/local/spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "import re\n",
    "from operator import add\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish reading source files\n"
     ]
    }
   ],
   "source": [
    "questionDataFrame = sqlContext.read.format(\"csv\").options(header=\"true\").load(\"Questions.csv\")\n",
    "answerDataFrame = sqlContext.read.format(\"csv\").options(header=\"true\").load(\"Answers.csv\")\n",
    "tagDataFrame = sqlContext.read.format(\"csv\").options(header=\"true\").load(\"Tags.csv\")\n",
    "\n",
    "print(\"finish reading source files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish reading stopwords: 671\n"
     ]
    }
   ],
   "source": [
    "stopWordsList = sc.textFile(\"stopwords.txt\").collect()\n",
    "print(\"finish reading stopwords: \" + str(len(stopWordsList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('80', \"sqlstatement execute multiple queries in one statement i've written a database generation script in sql and want to execute it in my adobe air application create table trole roleid integer primary key rolename varchar 40 create table tfile fileid integer primary key filename varchar 50 filedescription varchar 500 thumbnailid integer fileformatid integer categoryid integer isfavorite boolean dateadded date globalaccesscount integer lastaccesstime date downloadcomplete boolean isnew boolean isspotlight boolean duration varchar 30 create table tcategory categoryid integer primary key categoryname varchar 50 parent categoryid integer i execute this in adobe air using the following methods public static function runsqlfromfile filename string void var file file file applicationdirectory resolvepath filename var stream filestream new filestream stream open file filemode read var strsql string stream readutfbytes stream bytesavailable nonquery strsql public static function nonquery strsql string void var sqlconnection sqlconnection new sqlconnection sqlconnection open file applicationstoragedirectory resolvepath dbpath var sqlstatement sqlstatement new sqlstatement sqlstatement text strsql sqlstatement sqlconnection sqlconnection try sqlstatement execute catch error sqlerror alert show error tostring no errors are generated however only trole exists it seems that it only looks at the first query up to the semicolon if i remove it the query fails is there a way to call multiple queries in one statement \")]\n"
     ]
    }
   ],
   "source": [
    "questionLower = questionDataFrame.rdd.map(lambda x: (x[\"Id\"], re.sub(\"<.*?>\", \" \", (x[\"Title\"] + x[\"Body\"]).lower())))\n",
    "questionLower = questionLower.map(lambda x: (x[0], re.sub('[^a-zA-Z0-9\\']+', ' ', x[1])))\n",
    "print(questionLower.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('80', 'sqlstatement'), ('80', 'execute'), ('80', 'multiple'), ('80', 'queries'), ('80', 'statement'), ('80', 'written'), ('80', 'database'), ('80', 'generation'), ('80', 'script'), ('80', 'sql')]\n"
     ]
    }
   ],
   "source": [
    "def f2(x): return x.split(\" \")\n",
    "questionPair = questionLower.flatMapValues(f2).filter(lambda x: x[1] not in stopWordsList and x[1] != \"\")\n",
    "print(questionPair.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1757fc7773ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquestionPairStage1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquestionPair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"@\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestionPairStage1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m         \"\"\"\n\u001b[0;32m-> 1041\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1030\u001b[0m         \u001b[0;36m6.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \"\"\"\n\u001b[0;32m-> 1032\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mfold\u001b[0;34m(self, zeroValue, op)\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0;31m# zeroValue provided to each partition is unique from the one provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;31m# to the final reduce call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeroValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    807\u001b[0m         \"\"\"\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m             \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1133\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "questionPairStage1 = questionPair.map(lambda x:(x[0] + \"@\" + x[1], 1)).reduceByKey(add)\n",
    "print(questionPairStage1.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1264216\n"
     ]
    }
   ],
   "source": [
    "N = questionLower.count()\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('execute', '80=4'), ('multiple', '80=2'), ('statement', '80=2'), ('database', '80=1'), ('generation', '80=1')]\n"
     ]
    }
   ],
   "source": [
    "questionPairStage2MapPhase = questionPairStage1.map(lambda x: (x[0].split(\"@\")[1], x[0].split(\"@\")[0] + \"=\" + str(x[1])))\n",
    "print(questionPairStage2MapPhase.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2Map = questionPairStage2MapPhase.countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('execute@80', 11.128338413705677), ('multiple@80', 5.548688364952579), ('statement@80', 6.035776454821954), ('database@80', 2.583997552432231), ('generation@80', 4.663439094112067)]\n"
     ]
    }
   ],
   "source": [
    "questionPairStage2 = questionPairStage2MapPhase.map(lambda x: (x[0]+\"@\"+x[1].split(\"=\")[0], (1 + np.log(int(x[1].split(\"=\")[1]))) * np.log(N/stage2Map.get(x[0]))))\n",
    "print(questionPairStage2.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('80', 'execute=11.128338413705677'), ('80', 'multiple=5.548688364952579'), ('80', 'statement=6.035776454821954'), ('80', 'database=2.583997552432231'), ('80', 'generation=4.663439094112067')]\n"
     ]
    }
   ],
   "source": [
    "questionPairStage3MapPhase = questionPairStage2.map(lambda x: (x[0].split(\"@\")[1], x[0].split(\"@\")[0] + \"=\" + str(x[1])))\n",
    "print(questionPairStage3MapPhase.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('180', 229.7145562811237), ('330', 1341.3598263114907), ('470', 448.5714876428375), ('580', 2123.868076874934), ('930', 170.42691150448204)]\n"
     ]
    }
   ],
   "source": [
    "def f3_1(a,b): return float(a) + float(b.split(\"=\")[1]) * float(b.split(\"=\")[1])\n",
    "def f3_2(a,b): return float(a) + float(b)\n",
    "questionPairStage3AggByKey = questionPairStage3MapPhase.aggregateByKey(0.0, f3_1, f3_2)\n",
    "print(questionPairStage3AggByKey.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.038131748297413\n"
     ]
    }
   ],
   "source": [
    "stage3Map = questionPairStage3AggByKeysqr.collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('80', 'execute=0.18639896556738128'), ('80', 'multiple=0.09294017965962616'), ('80', 'statement=0.10109887440061487'), ('80', 'database=0.04328179579880556'), ('80', 'generation=0.07811231028509996'), ('80', 'http=0.061783416134000416'), ('80', 'en=0.0770694152873754'), ('80', 'wikipedia=0.10109887440061487'), ('80', 'wiki=0.10109887440061487'), ('80', 'adobe=0.13956220568671052')]\n"
     ]
    }
   ],
   "source": [
    "questionPairStage3 = questionPairStage3MapPhase.map(lambda x: (x[0], x[1].split(\"=\")[0] + \"=\" + str(float(x[1].split(\"=\")[1])/stage3Map.get(x[0]))))\n",
    "print(questionPairStage3.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('180', ['wheels=0.3076890572649864', 'pseudo=0.3076890572649864', 'solved=0.3076890572649864', 'stuck=0.3076890572649864', 'distinguishable=0.3076890572649864', 'parameter=0.2619558980603028', 'g=0']), ('330', ['classes=0.3193517411118351', 'video=0.227500315486462', 'workhorse=0.2155898812650258', 'book=0.2155898812650258', 'mine=0.18354582207600814', 'pause=0.12733085684478265', 'encoding=0.12733085684478265']), ('470', ['homegrown=0.3728079699966661', 'services=0.284981923834969', 'ready=0.22018639269940712', 'numerous=0.22018639269940712', 'opposed=0.22018639269940712', 'auto=0.22018639269940712', 'creates=0.22018639269940712']), ('580', ['live=0.2825013570494739', 'products=0.17133151385886897', 'scripts=0.17133151385886897', 'enterprise=0.17133151385886897', 'manager=0.17133151385886897', 'express=0.17133151385886897', 'gate=0.17133151385886897']), ('930', ['connect=0.5149298451290975', 'simplest=0.3572211977022691', 'loop=0.3572211977022691', 'recordset=0.3572211977022691', 'query=0.2339376451341581', 'f=0', 'g=0'])]\n"
     ]
    }
   ],
   "source": [
    "num_keywords = 7\n",
    "def f4_1(a,b):\n",
    "    c=[]\n",
    "    for i in range(num_keywords):\n",
    "        if float(b.split(\"=\")[1])>float(a[i].split(\"=\")[1]):\n",
    "            a[i]=b\n",
    "            break\n",
    "    return a\n",
    "def f4_2(a,b):\n",
    "    for i in range(num_keywords): #b\n",
    "        for j in range(num_keywords): #a\n",
    "            if float(b[i].split(\"=\")[1])>float(a[j].split(\"=\")[1]):\n",
    "                a[j] = b[i]\n",
    "                break\n",
    "    return a\n",
    "questionPairStage4 = questionPairStage3.aggregateByKey([\"a=0\", \"b=0\", \"c=0\", \"d=0\", \"e=0\", \"f=0\", \"g=0\"], f4_1, f4_2)\n",
    "print(questionPairStage4.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "outMap=questionPairStage4.collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['organization', 'ul', 'confirm', 'big', 'sqlstatement', 'wheel', 'languages', 'event', 'manager', 'syntax', 'providers', 'stacks', 'matching', 'objects', 'site', 'programming', 'best', 'ux', 'simple', 'create', 'explaining', 'dns', 'payload', 'times', 'heard', 'update', 'parameter', 'autocomplete', 'dataset', 'bit', 'updating', 'querying', 'simplest', 'ends', 'structure', 'homegrown', 'stuck', 'sqlconnection', 'cmdlets', 'replace', 'numerous', 'rspec', 'supports', 'stored', 'respective', 'bazaar', 'query', 'mysql', 'studio', 'terms', 'peak', 'hkey', 'verifications', 'resolvepath', 'trim', 'ado', 'icard', 'version', 'purchased', 'catching', 'winforms', 'cards', 'property', 'aix', 'c', 'values', 'bean', 'messy', 'br', 'today', 'questions', 'hashmaps', 'attempt', 'table', 'dim', 'gt', 'wheels', 'moment', 'datagrid', 'embedding', 'recordset', 'connect', 'net', 'simply', 'pm', 'choice', 'video', 'ruby', 'liba', 'playing', 'array', 'customusername', 'core', 'subversion', 'solo', 'cms', 'traverse', 'canonicalization', 'kbd', 'fogbugz', 'encoding', 'logically', 'postback', 'formattedstring', 'ms', 'services', 'seework', 'generate', 'close', 'locked', 'things', 'triggers', 'workhorse', 'object', 'displayed', 'compiled', 'publickeytoken', 'unit', 'onkeypress', 'rel', 'ironruby', 'surprise', 'sales', 'ready', 'd', 'menu', 'speeding', 'blending', 'microsoft', 'target', 'merging', 'subdomain', 'joins', 'shared', 'pseudo', 'code', 'card', 'php', 'specific', 'varchar', 'asterisk', 'field', 'task', 'framework', 'scripts', 'torgb', 'src', 'htaccess', 'presumably', 'book', 'g', 'regex', 'allow', 'send', 'handles', 'straight', 'community', 'database', 'prototype', 'match', 'complicated', 'vectors', 'solaris', 'porv', 'todo', 'free', 'forums', 'views', 'wmi', 'major', 'getters', 'tortoisesvn', 'telligent', 'third', 'exceptions', 'windows', 'tables', 'tools', 'coverage', 'datatable', 'global', 'soloing', 'example', 'classes', 'writing', 'clicking', 'ol', 'internet', 'realize', 'points', 'box', 'release', 'blockquote', 'system', 'trouble', 'branchmerge', 'unsupported', 'datastructures', 'signed', 'server', 'method', 'modifiers', 'vsz', 'add', 'libb', 'registry', 'regexoptions', 'exactly', 'js', 'machine', 'lt', 'versions', 'build', 'local', 'datatables', 'device', 'sitemap', 'form', 'organize', 'codes', 'ordering', 'products', 'procs', 'collection', 'li', 'solution', 'browse', 'asp', 'procedures', 'cc', 'figuring', 'language', 'class', 'xml', 'setters', 'pointed', 'source', 'bin', 'address', 'suffice', 'uncomfortable', 'opposed', 'sharepoint', 'basecamp', 'paper', 'hkcu', 'base', 'echo', 'handling', 'locking', 'setter', 'live', 'postgresql', 'hand', 'subquery', 'sql', 'solved', 'faster', 'queries', 'management', 'msbuild', 'story', 'edit', 'paging', 'emma', 'based', 'folder', 'gridview', 'string', 'size', 'blend', 'readings', 'good', 'refresh', 'properly', 'modify', 'bring', 'hp', 'eclipse', 'input', 'analysis', 'initial', 'testing', 'creating', 'namespace', 'figure', 'visual', 'column', 'ps', 'newhour', 'em', 'classic', 'fairly', 'creates', 'prone', 'suspect', 'layer', 'appealing', 'barebones', 'redistributable', 'comparable', 'control', 'stream', 'white', 'backticks', 'md', 'crap', 'assemblyversion', 'wise', 'design', 'spec', 'location', 'uhwc', 'f', 'web', 'incremented', 'delta', 'packages', 'viewstate', 'void', 'git', 'pause', 'whois', 'mine', 'express', 'daterequired', 'color', 'branching', 'return', 'years', 'email', 'enterprise', 'processcmdkey', 'search', 'changes', 'interacts', 'practice', 'columns', 'title', 'ccnet', 'stl', 'description', 'restore', 'hashbytes', 'storage', 'suggested', 'reasons', 'wrapped', 'bodmas', 'deques', 'disable', 'e', 'love', 'utility', 'urple', 'nonquery', 'favorite', 'njc', 'auto', 'overhead', 'reason', 'wildcard', 'users', 'versus', 'netcmdlets', 'dlls', 'delete', 'view', 'loop', 'rake', 'wiki', 'visualise', 'strsql', 'effective', 'asax', 'username', 'support', 'service', 'bll', 'row', 'gate', 'learn', 'decent', 'distinguishable', 'process', 'informed', 'strong', 'painted', 'hours', 'personal', 'clauses', 'treemaps', 'suite', 'glance', 'nant']\n"
     ]
    }
   ],
   "source": [
    "# mock expected keywords\n",
    "keywords=list(set(questionPairStage4.map(lambda x: list(map((lambda x: x.split(\"=\")[0]), x[1]))).reduce(add)))\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" I've written a database generation script in SQL and want to execute it in my Adobe AIR application Create Table tRole roleID integer Primary Key roleName varchar Create Table tFile fileID integer Primary Key fileName varchar fileDescription varchar thumbnailID integer fileFormatID integer categoryID integer isFavorite boolean dateAdded date globalAccessCount integer lastAccessTime date downloadComplete boolean isNew boolean isSpotlight boolean duration varchar Create Table tCategory categoryID integer Primary Key categoryName varchar parent categoryID integer I execute this in Adobe AIR using the following methods public static function RunSqlFromFile fileName String void var file File File applicationDirectory resolvePath fileName var stream FileStream new FileStream stream open file FileMode READ var strSql String stream readUTFBytes stream bytesAvailable NonQuery strSql public static function NonQuery strSQL String void var sqlConnection SQLConnection new SQLConnection sqlConnection open File applicationStorageDirectory resolvePath DBPATH var sqlStatement SQLStatement new SQLStatement sqlStatement text strSQL sqlStatement sqlConnection sqlConnection try sqlStatement execute catch error SQLError Alert show error toString No errors are generated however only tRole exists It seems that it only looks at the first query up to the semicolon if I remove it the query fails Is there a way to call multiple queries in one statement \"]\n"
     ]
    }
   ],
   "source": [
    "newQuestion = sc.wholeTextFiles(\"new_q.txt\")\n",
    "newQuestion = newQuestion.map(lambda x: re.sub('\\n', ' ', x[1]))\n",
    "newQuestion = newQuestion.map(lambda x: re.sub('<.*?>', ' ', x))\n",
    "newQuestion = newQuestion.map(lambda x: re.sub('[^a-zA-Z\\']+', ' ', x))\n",
    "\n",
    "print(newQuestion.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('written', 'new=1'), ('database', 'new=1'), ('generation', 'new=1'), ('script', 'new=1'), ('sql', 'new=1'), ('execute', 'new=3'), ('adobe', 'new=2'), ('air', 'new=2'), ('application', 'new=1'), ('create', 'new=3')]\n"
     ]
    }
   ],
   "source": [
    "newQuestionKeywordsStageOne = newQuestion.flatMap(lambda x: x.lower().split(\" \")).filter(lambda x: x != '' and x not in stopWordsList).map(lambda x: (x, 1)).reduceByKey(add).map(lambda x: (x[0], 'new=' + str(x[1])))\n",
    "print(newQuestionKeywordsStageOne.take(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('written', 3.574216545793796), ('database', 2.4756042571256867), ('generation', 3.979681653901961), ('script', 3.0633909220278057), ('sql', 2.033771504846648), ('execute', 8.351808823865683), ('adobe', 6.051674667221473), ('air', 6.738186771830246), ('application', 2.4756042571256867), ('create', 5.442514441908174)]\n"
     ]
    }
   ],
   "source": [
    "newQuestionKeywordsStageTwoMap = newQuestionKeywordsStageOne.union(questionPairStage2MapPhase).countByKey()\n",
    "\n",
    "newQuestionKeywordsStageTwo = newQuestionKeywordsStageOne.map(lambda x: (x[0], (1 + np.log(int(x[1].split(\"=\")[1]))) * np.log((N + 1)/newQuestionKeywordsStageTwoMap.get(x[0]))))\n",
    "print(newQuestionKeywordsStageTwo.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('written', 0.07247168990263128), ('database', 0.050195958119879744), ('generation', 0.08069299972106751), ('script', 0.06211406446903707), ('sql', 0.04123724904287243), ('execute', 0.16934332082412465), ('adobe', 0.12270523742905481), ('air', 0.13662512496864992), ('application', 0.050195958119879744), ('create', 0.11035375553524643), ('table', 0.11035375553524643), ('trole', 0.13662512496864992), ('roleid', 0.08069299972106751), ('integer', 0.22317233248190185), ('primary', 0.16934332082412465), ('key', 0.13984853817968554), ('rolename', 0.08069299972106751), ('varchar', 0.18911037521009366), ('tfile', 0.08069299972106751), ('fileid', 0.08069299972106751), ('filename', 0.16934332082412465), ('filedescription', 0.08069299972106751), ('thumbnailid', 0.08069299972106751), ('fileformatid', 0.08069299972106751), ('categoryid', 0.16934332082412465), ('isfavorite', 0.08069299972106751), ('boolean', 0.19255725021623232), ('dateadded', 0.08069299972106751), ('globalaccesscount', 0.08069299972106751), ('lastaccesstime', 0.08069299972106751), ('downloadcomplete', 0.08069299972106751), ('isnew', 0.08069299972106751), ('isspotlight', 0.08069299972106751), ('duration', 0.08069299972106751), ('tcategory', 0.08069299972106751), ('categoryname', 0.08069299972106751), ('parent', 0.08069299972106751), ('methods', 0.06211406446903707), ('public', 0.1051682531288688), ('static', 0.11282892004536968), ('function', 0.09361693687426799), ('runsqlfromfile', 0.08069299972106751), ('string', 0.12259519636576749), ('void', 0.13662512496864992), ('var', 0.21056337274018783), ('file', 0.13721508971812602), ('applicationdirectory', 0.08069299972106751), ('resolvepath', 0.13662512496864992), ('stream', 0.19255725021623232), ('filestream', 0.13662512496864992)]\n"
     ]
    }
   ],
   "source": [
    "newQuestionKeywordsStageThreeSquare = newQuestionKeywordsStageTwo.map(lambda x: np.square(x[1])).reduce(add)\n",
    "\n",
    "newQuestionKeywordsStageThree = newQuestionKeywordsStageTwo.map(lambda x: (x[0], x[1]/np.sqrt(newQuestionKeywordsStageThreeSquare)))\n",
    "print(newQuestionKeywordsStageThree.take(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sqlconnection', 0.22527544607170702), ('sqlstatement', 0.22527544607170702), ('stream', 0.19255725021623232), ('strsql', 0.19255725021623232), ('varchar', 0.18911037521009366), ('void', 0.13662512496864992), ('resolvepath', 0.13662512496864992), ('nonquery', 0.13662512496864992), ('string', 0.12259519636576749), ('create', 0.11035375553524643), ('table', 0.11035375553524643), ('query', 0.09890903250577458), ('queries', 0.058417267938315975), ('database', 0.050195958119879744), ('sql', 0.04123724904287243)]\n"
     ]
    }
   ],
   "source": [
    "newQuestionKeywordsStageFour = newQuestionKeywordsStageThree.filter(lambda x: x[0] in keywords).sortBy(lambda x: -x[1])\n",
    "print(newQuestionKeywordsStageFour.take(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sqlconnection', 'sqlstatement', 'stream', 'strsql', 'varchar']\n"
     ]
    }
   ],
   "source": [
    "# mock expected questions inside buckets <Qi, sum(Ai)>\n",
    "candidateSimilarQuestions = newQuestionKeywordsStageFour.map(lambda x: x[0])\n",
    "print(candidateSimilarQuestions.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate shingles\n",
    "# [word[i:i + n] for i in range(len(word) - n + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "from datasketch.minhash import MinHash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
